{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AarishB/FragrAI/blob/main/FragrAIi_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpNht0png3v4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from IPython.display import display\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "\n",
        "# === STEP 1: Load and clean dataset ===\n",
        "df = pd.read_csv('perfumes_table.csv', nrows=10000)\n",
        "df = df.drop(columns=['url', 'rating', 'reviews'], errors='ignore')\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Reorder columns\n",
        "desired_order = ['title', 'notes', 'description']\n",
        "remaining_cols = [col for col in df.columns if col not in desired_order]\n",
        "df = df[desired_order + remaining_cols]\n",
        "\n",
        "# Capitalize designer\n",
        "def capitalize(s):\n",
        "    if not isinstance(s, str): return s\n",
        "    exceptions = {'and', 'for', 'of', 'the', 'in', 'on', 'at', 'with', 'a', 'an'}\n",
        "    words = s.split()\n",
        "    return ' '.join([\n",
        "        word.capitalize() if i == 0 or word not in exceptions else word\n",
        "        for i, word in enumerate(words)\n",
        "    ])\n",
        "df['designer'] = df['designer'].apply(capitalize)\n",
        "\n",
        "def strip_accents(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))\n",
        "\n",
        "def canon_note(x): #these two methods help make unusual notes appear readable, used help from ChatGPT to get a regex pattern.\n",
        "    if not isinstance(x, str): return None\n",
        "    n = strip_accents(x).lower()\n",
        "    n = re.sub(r'[^a-z0-9\\s]', ' ', n).strip()\n",
        "    synonyms = {\n",
        "        'calabrian bergamot':'bergamot','sicilian bergamot':'bergamot','italian bergamot':'bergamot',\n",
        "        'cedarwood':'cedar','virginia cedar':'cedar','atlas cedar':'cedar',\n",
        "        'oudh':'oud','agarwood':'oud','oud wood':'oud',\n",
        "        'pink pepper':'pepper','black pepper':'pepper',\n",
        "        'white musk':'musk','ambroxan':'amber','ambergris':'amber',\n",
        "        'sea notes':'marine','marine notes':'marine','watery notes':'marine','aqua':'marine','calone':'marine',\n",
        "        'orange blossom':'neroli','orris root':'iris','cashmeran':'woody'\n",
        "    }\n",
        "    n = synonyms.get(n, n)\n",
        "    return ' '.join(w.capitalize() for w in n.split())\n",
        "\n",
        "def _extract_layer(text, layer_aliases, stop_regex):\n",
        "    if not isinstance(text, str): return []\n",
        "    s = ' '.join(text.split())  # flatten newlines/spaces\n",
        "\n",
        "    # RegEX pattern for identification\n",
        "    pat = rf\"\\b({'|'.join(layer_aliases)})\\s*(?:notes?)?\\s*(?:are|include|:)?\\s*(.*?)(?={stop_regex}|\\.|$)\"\n",
        "\n",
        "    m = re.search(pat, s, flags=re.IGNORECASE)\n",
        "    if not m:\n",
        "        return []\n",
        "    chunk = m.group(2)\n",
        "    toks = re.split(r'[;,/|]', chunk)\n",
        "    return [canon_note(t) for t in toks if canon_note(t)]\n",
        "\n",
        "def extract_notes(desc, note_type): #Better extraction of notes, which is more efficient and structured.\n",
        "    aliases = {\n",
        "        'Top': ['top','opening','head'],\n",
        "        'Middle': ['middle','heart'],\n",
        "        'Base': ['base','drydown']\n",
        "    }\n",
        "    if note_type == 'Top':\n",
        "        stop = r\"\\b(?:middle|heart|base|drydown)\\b\"\n",
        "    elif note_type == 'Middle':\n",
        "        stop = r\"\\b(?:base|drydown)\\b\"\n",
        "    else:\n",
        "        # match until period or end (stop regex that never matches)\n",
        "        stop = r\"$^\"\n",
        "\n",
        "    return _extract_layer(desc, aliases[note_type], stop)\n",
        "\n",
        "# Re-run extraction\n",
        "df['top_notes']    = df['description'].apply(lambda x: extract_notes(x, \"Top\"))\n",
        "df['middle_notes'] = df['description'].apply(lambda x: extract_notes(x, \"Middle\"))\n",
        "df['base_notes']   = df['description'].apply(lambda x: extract_notes(x, \"Base\"))\n",
        "\n",
        "if 'notes' in df.columns: #This section incorporates the cannon notes to make notes more broad and general, and outpu\n",
        "    def fallback(row):\n",
        "        if row['top_notes'] or row['middle_notes'] or row['base_notes']: return row\n",
        "        raw = row['notes']\n",
        "        if isinstance(raw, str):\n",
        "            toks = [canon_note(t) for t in re.split(r'[;,/|]', raw) if canon_note(t)]\n",
        "            row['top_notes'] = toks\n",
        "        elif isinstance(raw, (list, tuple)):\n",
        "            row['top_notes'] = [canon_note(t) for t in raw if canon_note(t)]\n",
        "        return row\n",
        "    df = df.apply(fallback, axis=1)\n",
        "\n",
        "# === STEP 3: Create combined notes with weight for base notes ===\n",
        "df['combined_notes'] = df.apply(lambda row: row['top_notes'] + row['middle_notes'] + row['base_notes'] * 2, axis=1)\n",
        "\n",
        "# === STEP 4: Assign seasons for supervised learning ===\n",
        "seasonal_notes = {\n",
        "    'Summer': ['Citrus', 'Aquatic', 'Mint', 'Neroli', 'Grapefruit', 'Orange', 'Lemon', 'Bergamot'],\n",
        "    'Winter': ['Vanilla', 'Amber', 'Oud', 'Leather', 'Tobacco', 'Cinnamon', 'Tonka'],\n",
        "    'Spring': ['Jasmine', 'Rose', 'Green Tea', 'Lily', 'Pear', 'Apple'],\n",
        "    'Fall': ['Sandalwood', 'Patchouli', 'Nutmeg', 'Cardamom', 'Clove', 'Plum']\n",
        "}\n",
        "\n",
        "def assign_weighted_season_from_layers(top, mid, base):\n",
        "    season_scores = {season: 0 for season in seasonal_notes}\n",
        "    total_notes = len(top) + len(mid) + len(base)\n",
        "\n",
        "    if total_notes == 0:\n",
        "        return 'Inconclusive'\n",
        "\n",
        "    top_wt = max(1, round((len(top)/total_notes) * 10))\n",
        "    mid_wt = max(1, round((len(mid)/total_notes) * 10))\n",
        "    base_wt = max(1, round((len(base)/total_notes) * 10))\n",
        "\n",
        "    for note in top:\n",
        "        for season, group in seasonal_notes.items():\n",
        "            if note in group:\n",
        "                season_scores[season] += (top_wt+365)\n",
        "    for note in mid:\n",
        "        for season, group in seasonal_notes.items():\n",
        "            if note in group:\n",
        "                season_scores[season] += mid_wt\n",
        "    for note in base:\n",
        "        for season, group in seasonal_notes.items():\n",
        "            if note in group:\n",
        "                season_scores[season] += base_wt\n",
        "\n",
        "    return max(season_scores, key=season_scores.get) if any(season_scores.values()) else 'Inconclusive'\n",
        "\n",
        "df['season'] = df.apply(\n",
        "    lambda row: assign_weighted_season_from_layers(row['top_notes'], row['middle_notes'], row['base_notes']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# === STEP 5: Train ML model ===\n",
        "mlb = MultiLabelBinarizer()\n",
        "X = mlb.fit_transform(df['combined_notes'])\n",
        "y = df['season']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# === STEP 6: Evaluate model ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# === STEP 7: Predict on full dataset and show notes ===\n",
        "df['predicted_season'] = clf.predict(X)\n",
        "\n",
        "# === STEP 8: Display results with notes used ===\n",
        "pd.set_option('display.max_rows', 5000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "display(df[['title', 'designer', 'top_notes', 'middle_notes', 'base_notes', 'combined_notes', 'predicted_season']].head(10000))\n",
        "\n",
        "# === STEP 9: Analyze no-note descriptions ===\n",
        "no_notes_df = df[\n",
        "    (df['top_notes'].apply(len) == 0) &\n",
        "    (df['middle_notes'].apply(len) == 0) &\n",
        "    (df['base_notes'].apply(len) == 0)\n",
        "]\n",
        "\n",
        "print(f\"\\nTotal fragrances with no extracted notes: {len(no_notes_df)}\\n\")\n",
        "\n",
        "# Count recurring fragments (even without filtering)\n",
        "phrases = []\n",
        "for desc in no_notes_df['description'].dropna().head(200):\n",
        "    lines = desc.lower().split('.')\n",
        "    phrases.extend([line.strip() for line in lines if line.strip()])\n",
        "\n",
        "common = Counter(phrases)\n",
        "print(\"Most common sentence fragments in no-note descriptions:\")\n",
        "for phrase, count in common.most_common(30):\n",
        "    print(f\"{count} â†’ {phrase}\")\n",
        "\n",
        "# === STEP 10: Show 5 full descriptions that had no extracted notes ===\n",
        "print(\"\\n\\nExamples of full descriptions with no extracted notes:\")\n",
        "for i, desc in enumerate(no_notes_df['description'].dropna().head(5), 1):\n",
        "    print(f\"\\n{i}. {desc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}